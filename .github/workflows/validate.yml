name: Validate Framework

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

permissions:
  contents: read

jobs:
  validate-yaml:
    name: Validate YAML
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install dependencies
        run: pip install pyyaml

      - name: Validate CONFIG.yaml
        run: |
          python3 - <<'PY'
          import yaml

          with open("CONFIG.yaml", "r", encoding="utf-8") as file:
              yaml.safe_load(file)

          print("CONFIG.yaml: OK")
          PY

      - name: Validate all YAML files
        run: |
          EXIT_CODE=0
          while IFS= read -r file; do
            if python3 -c "import yaml; yaml.safe_load(open('$file'))" 2>/dev/null; then
              echo "OK: $file"
            else
              echo "FAIL: $file"
              EXIT_CODE=1
            fi
          done < <(find . -name "*.yaml" -o -name "*.yml" | grep -v '.github/' | grep -v 'node_modules/')
          exit $EXIT_CODE

  validate-markdown:
    name: Validate Markdown
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Check for broken internal links and cross-file references
        run: |
          python3 - <<'PY'
          import re
          import sys
          from pathlib import Path

          repo = Path(".").resolve()

          md_files = [
            p for p in repo.rglob("*.md")
            if ".git" not in p.parts
            and "node_modules" not in p.parts
            and "_TEMPLATE" not in p.name
          ]

          inline_link_pattern = re.compile(r"\[[^\]]*\]\(([^)]+)\)")
          reference_use_pattern = re.compile(r"\[[^\]]+\]\[([^\]]+)\]")
          reference_def_pattern = re.compile(r"^\s*\[([^\]]+)\]:\s*(\S+)", re.MULTILINE)
          heading_pattern = re.compile(r"^#{1,6}\s+(.+?)\s*$", re.MULTILINE)

          def normalize_anchor(text: str) -> str:
            value = text.strip().lower()
            value = re.sub(r"[`*_~\[\](){}.!?,:;\"'\\\\]", "", value)
            value = re.sub(r"\s+", "-", value)
            value = re.sub(r"-+", "-", value).strip("-")
            return value

          def is_external(target: str) -> bool:
            lower = target.lower()
            return (
              lower.startswith("http://")
              or lower.startswith("https://")
              or lower.startswith("mailto:")
              or lower.startswith("tel:")
              or lower.startswith("ftp://")
            )

          def parse_target(raw: str):
            cleaned = raw.strip()
            if cleaned.startswith("<") and cleaned.endswith(">"):
              cleaned = cleaned[1:-1].strip()
            if " " in cleaned:
              cleaned = cleaned.split(" ", 1)[0]
            if "{{" in cleaned:
              return None, None, True
            if is_external(cleaned):
              return None, None, True
            if cleaned.startswith("#"):
              return "", cleaned[1:], False
            path_part, anchor = (cleaned.split("#", 1) + [""])[:2] if "#" in cleaned else (cleaned, "")
            return path_part, anchor, False

          def resolve_path(source: Path, path_part: str) -> Path:
            if path_part.startswith("/"):
              target = repo / path_part.lstrip("/")
            else:
              target = (source.parent / path_part).resolve()
            return target

          heading_cache = {}

          def get_headings(md_file: Path):
            if md_file in heading_cache:
              return heading_cache[md_file]
            text = md_file.read_text(encoding="utf-8", errors="ignore")
            anchors = {normalize_anchor(m.group(1)) for m in heading_pattern.finditer(text)}
            heading_cache[md_file] = anchors
            return anchors

          broken = []

          for md_file in md_files:
            text = md_file.read_text(encoding="utf-8", errors="ignore")

            ref_defs = {
              key.strip().lower(): value.strip()
              for key, value in reference_def_pattern.findall(text)
            }

            candidates = [match.group(1).strip() for match in inline_link_pattern.finditer(text)]

            for ref_key in reference_use_pattern.findall(text):
              ref_target = ref_defs.get(ref_key.strip().lower())
              if ref_target:
                candidates.append(ref_target)

            for candidate in candidates:
              path_part, anchor, skip = parse_target(candidate)
              if skip:
                continue

              target_file = md_file if path_part == "" else resolve_path(md_file, path_part)

              try:
                target_file.relative_to(repo)
              except ValueError:
                broken.append((md_file, candidate, "target escapes repository"))
                continue

              if not target_file.exists():
                broken.append((md_file, candidate, "target does not exist"))
                continue

              if anchor:
                if target_file.suffix.lower() == ".md":
                  anchors = get_headings(target_file)
                  normalized = normalize_anchor(anchor)
                  if normalized not in anchors:
                    broken.append((md_file, candidate, f"missing anchor #{anchor}"))

          if broken:
            print("Broken markdown links found:")
            for src, link, reason in broken:
              print(f"- {src.relative_to(repo)} -> {link} ({reason})")
            print(f"\nTotal broken links: {len(broken)}")
            sys.exit(1)

          print(f"Checked {len(md_files)} markdown files: all internal links OK")
          PY

  validate-placeholders:
    name: Check Placeholders (blocking)
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Self-check (script integrity)
        run: python3 scripts/check_placeholders.py --self-check

      - name: Check for unfilled placeholders in non-template docs
        run: |
          python3 scripts/check_placeholders.py
          # Exit code 1 = violations found → CI fails (blocking check)
          # See docs/PLACEHOLDER-CHECK.md for patterns detected and opt-out instructions.

  validate-structure:
    name: Validate Structure
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Check required files exist
        run: |
          REQUIRED_FILES=(
            "README.md"
            "AGENTS.md"
            "CONFIG.yaml"
            "COMPANY.md"
            "CONTRIBUTING.md"
            "OPERATING-MODEL.md"
            "CODEOWNERS"
            "LICENSE"
            "org/README.md"
            "process/README.md"
            "work/README.md"
          )
          MISSING=0
          for f in "${REQUIRED_FILES[@]}"; do
            if [[ -f "$f" ]]; then
              echo "OK: $f"
            else
              echo "MISSING: $f"
              MISSING=$((MISSING + 1))
            fi
          done
          if [ $MISSING -gt 0 ]; then
            echo "$MISSING required file(s) missing"
            exit 1
          fi

      - name: Check layer structure
        run: |
          for layer in 0-steering 1-strategy 2-orchestration 3-execution 4-quality; do
            if [[ ! -f "org/$layer/AGENT.md" ]]; then
              echo "MISSING: org/$layer/AGENT.md"
              exit 1
            fi
            echo "OK: org/$layer/AGENT.md"
          done

      - name: Check process loops
        run: |
          for loop in 1-discover 2-build 3-ship 4-operate; do
            for file in AGENT.md GUIDE.md; do
              if [[ ! -f "process/$loop/$file" ]]; then
                echo "MISSING: process/$loop/$file"
                exit 1
              fi
              echo "OK: process/$loop/$file"
            done
          done

  validate-versioning:
    name: Validate Versioning
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Resolve diff base and head
        id: refs
        run: |
          if [ "${{ github.event_name }}" = "pull_request" ]; then
            echo "base=${{ github.event.pull_request.base.sha }}" >> "$GITHUB_OUTPUT"
            echo "head=${{ github.event.pull_request.head.sha }}" >> "$GITHUB_OUTPUT"
          else
            BEFORE="${{ github.event.before }}"
            # All-zeros means initial push or force-push with no common ancestor — skip diff
            if echo "$BEFORE" | grep -qE '^0+$'; then
              echo "base=" >> "$GITHUB_OUTPUT"
            else
              echo "base=$BEFORE" >> "$GITHUB_OUTPUT"
            fi
            echo "head=${{ github.sha }}" >> "$GITHUB_OUTPUT"
          fi

      - name: Check version fields and changelog sections exist in governed files
        run: |
          python3 - <<'PY'
          import re
          import sys
          from pathlib import Path

          VERSION_RE = re.compile(r"\*\*Version:\*\*\s*\d+\.\d+")
          TEMPLATE_VERSION_RE = re.compile(r"\*\*Template version:\*\*\s*\d+\.\d+")
          CHANGELOG_RE = re.compile(r"^## Changelog\s*$", re.MULTILINE)

          repo = Path(".")
          errors = []

          def check_file(path, version_pattern, label):
              text = path.read_text(encoding="utf-8")
              if not version_pattern.search(text):
                  errors.append(f"MISSING version field ({label}): {path}")
              elif not CHANGELOG_RE.search(text):
                  errors.append(f"MISSING '## Changelog' section ({label}): {path}")
              else:
                  print(f"OK: {path}")

          # Check layer AGENT.md files
          for layer in ["0-steering", "1-strategy", "2-orchestration", "3-execution", "4-quality"]:
              path = repo / f"org/{layer}/AGENT.md"
              if path.exists():
                  check_file(path, VERSION_RE, "layer AGENT.md")

          # Check process loop AGENT.md files
          for loop in ["1-discover", "2-build", "3-ship", "4-operate"]:
              path = repo / f"process/{loop}/AGENT.md"
              if path.exists():
                  check_file(path, VERSION_RE, "process AGENT.md")

          # Check quality policy files
          policies_dir = repo / "org/4-quality/policies"
          for policy_file in sorted(policies_dir.glob("*.md")):
              check_file(policy_file, VERSION_RE, "quality policy")

          # Check template files
          for template_file in sorted(repo.rglob("_TEMPLATE-*.md")):
              if ".git" in template_file.parts:
                  continue
              check_file(template_file, TEMPLATE_VERSION_RE, "template")

          # Check CONFIG.yaml has framework_version
          config = repo / "CONFIG.yaml"
          if config.exists():
              text = config.read_text(encoding="utf-8")
              if not re.search(r'^framework_version:', text, re.MULTILINE):
                  errors.append("MISSING framework_version field in CONFIG.yaml")
              else:
                  print("OK: CONFIG.yaml (framework_version)")

          # Check CHANGELOG.md exists
          changelog = repo / "CHANGELOG.md"
          if not changelog.exists():
              errors.append("MISSING CHANGELOG.md at repository root")
          else:
              print("OK: CHANGELOG.md")

          if errors:
              print(f"\n{len(errors)} versioning error(s) found:")
              for e in errors:
                  print(f"  ✗ {e}")
              print("\nEvery governed file must have: version field + ## Changelog section.")
              print("See AGENTS.md Rule 10 and CHANGELOG.md for conventions.")
              sys.exit(1)

          print(f"\nAll governed files have required version fields and changelog sections.")
          PY

      - name: Check changed files have updated version/date
        env:
          BASE: ${{ steps.refs.outputs.base }}
          HEAD: ${{ steps.refs.outputs.head }}
        run: |
          python3 - <<'PY'
          import os
          import re
          import subprocess
          import sys
          from pathlib import Path

          BASE = os.environ.get("BASE", "").strip()
          HEAD = os.environ.get("HEAD", "").strip()

          if not BASE:
              print("No base SHA available (initial push or force-push) — skipping diff check.")
              sys.exit(0)

          # Get list of changed .md files between base and head
          result = subprocess.run(
              ["git", "diff", "--name-only", BASE, HEAD],
              capture_output=True, text=True
          )
          changed_files = [f.strip() for f in result.stdout.splitlines() if f.strip().endswith(".md")]

          # Patterns for version and date fields
          VERSION_RE = re.compile(r"\*\*Version:\*\*\s*[\d.]+")
          TEMPLATE_VERSION_RE = re.compile(r"\*\*Template version:\*\*\s*[\d.]+")
          LAST_UPDATED_RE = re.compile(r"\*\*Last updated:\*\*\s*\d{4}-\d{2}-\d{2}")
          REVISION_RE = re.compile(r"\*\*Revision:\*\*\s*\d+")

          # Govened path patterns and what we check
          GOVERNED = [
              ("org/*/AGENT.md", LAST_UPDATED_RE, "Last updated date"),
              ("org/4-quality/policies/*.md", LAST_UPDATED_RE, "Last updated date"),
              ("*/_TEMPLATE-*.md", LAST_UPDATED_RE, "Last updated date"),
          ]

          errors = []
          warnings = []

          for changed in changed_files:
              path = Path(changed)

              # Determine if this file is governed
              is_agent_md = path.name == "AGENT.md" and path.parts[0] == "org"
              is_policy = "4-quality/policies" in str(path) and path.suffix == ".md"
              is_template = "_TEMPLATE-" in path.name

              if not (is_agent_md or is_policy or is_template):
                  continue

              if not path.exists():
                  continue  # File was deleted — skip

              # Get current content
              current_text = path.read_text(encoding="utf-8")

              # Get base content for comparison
              base_result = subprocess.run(
                  ["git", "show", f"{BASE}:{changed}"],
                  capture_output=True, text=True
              )
              if base_result.returncode != 0:
                  # New file — just check it has the field
                  if is_template and not TEMPLATE_VERSION_RE.search(current_text):
                      errors.append(f"NEW template file missing 'Template version' field: {changed}")
                  elif (is_agent_md or is_policy) and not LAST_UPDATED_RE.search(current_text):
                      errors.append(f"NEW governed file missing 'Last updated' field: {changed}")
                  else:
                      print(f"OK (new file): {changed}")
                  continue

              base_text = base_result.stdout

              # Check that Last updated date changed
              current_dates = LAST_UPDATED_RE.findall(current_text)
              base_dates = LAST_UPDATED_RE.findall(base_text)

              if not current_dates:
                  errors.append(f"MISSING 'Last updated' field in changed file: {changed}")
              elif current_dates == base_dates:
                  # Date unchanged — for templates, also accept a Template version bump
                  # (handles same-day create+modify where the date cannot advance)
                  if is_template:
                      current_versions = TEMPLATE_VERSION_RE.findall(current_text)
                      base_versions = TEMPLATE_VERSION_RE.findall(base_text)
                      if current_versions != base_versions:
                          print(f"OK (template version bumped): {changed} {base_versions} → {current_versions}")
                      else:
                          errors.append(
                              f"'Last updated' date NOT bumped in changed file: {changed}\n"
                              f"  Current: {current_dates}\n"
                              f"  Base:    {base_dates}\n"
                              f"  → Update the 'Last updated' date (or bump Template version) when modifying a template."
                          )
                  else:
                      errors.append(
                          f"'Last updated' date NOT bumped in changed file: {changed}\n"
                          f"  Current: {current_dates}\n"
                          f"  Base:    {base_dates}\n"
                          f"  → Update the 'Last updated' date when modifying a governed file."
                      )
              else:
                  print(f"OK (date bumped): {changed} {base_dates} → {current_dates}")

          if errors:
              print("\nVersioning enforcement failures:")
              for e in errors:
                  print(f"  ✗ {e}")
              print("\nTo fix: update the 'Last updated' field in each failing file.")
              sys.exit(1)

          print("\nAll changed governed files have updated version/date fields.")
          PY

  validate-github-governance:
    name: Validate GitHub Governance (advisory)
    runs-on: ubuntu-latest
    permissions:
      contents: read
    steps:
      - uses: actions/checkout@v4
      - name: "Advisory check: CODEOWNERS + branch protection"
        env:
          GITHUB_DEFAULT_BRANCH: "${{ github.event.repository.default_branch || 'main' }}"
        run: |
          python3 scripts/check_github_governance.py

  validate-schema:
    name: Validate Schemas
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install dependencies
        run: pip install pyyaml jsonschema

      - name: Validate CONFIG.yaml and work artifact schemas
        run: python3 scripts/validate_schema.py
